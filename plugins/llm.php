<?php

/**
 * run an llm query - supports multiple openai-compatible services
 *
 * note default $llm_config vars below can be modified after plugin inclusion in bot settings file without changing this file
 * see https://github.com/dhjw/php-irc-bot?tab=readme-ov-file#including-plugin-files
 * 
 * github pastes are same as with llm-gemini.php plugin (for gemini with native features) - can use same github user/repo/key/page
 */

// config
$llm_config = [
    "services" => [
        [
            "name" => "ChatGPT", // service name, sent with GitHub results, if enabled, for use by the view page for e.g. images. could also be used in result link titles
            "trigger" => "!gpt", // irc command
            "base_url" => "https://api.openai.com/v1", // no trailing slash
            "key" => "", // https://platform.openai.com/api-keys
            "model" => "gpt-4o-mini", // https://platform.openai.com/docs/models
            "vision_model" => "gpt-4o-mini",
        ],
        [
            "name" => "Grok",
            "trigger" => "!grok",
            "base_url" => "https://api.x.ai/v1",
            "key" => "", // https://console.x.ai/
            "model" => "grok-3-mini", // https://docs.x.ai/docs/models
            "vision_model" => "grok-2-vision",
            "grok_search_enabled" => false, // https://docs.x.ai/docs/guides/live-search. $25 USD per 1K searches in July 2025
            "grok_search_max_results" => 15, // 1-30
            "grok_search_mode" => "auto", // off, auto, on
            "grok_search_sources" => ["web", "x", "news"], // web, x, news
            "grok_search_safe" => false, // only safe results
        ],
        // [
        //     "name" => "Gemini", // note: "Gemini" (case-sensitive) set here is used to determine whether to only send data uris, and not urls, to the vision model. note llm-gemini.php plugin uses the native endpoint and has more features
        //     "trigger" => "!gem",
        //     "base_url" => "https://generativelanguage.googleapis.com/v1beta/openai",
        //     "key" => "", // https://aistudio.google.com/apikey
        //     "model" => "gemini-2.5-flash-preview-05-20", // https://ai.google.dev/gemini-api/docs/models
        //     "vision_model" => "gemini-2.5-flash-preview-05-20",
        // ],
    ],
    "github_enabled" => true, // upload responses beyond X lines to github and output the link instead, e.g. https://user.github.io/?id
    // how to setup github:
    // create a user and a repo with the name user.github.io (use your username)
    // in user Settings > Developer settings > Personal Access Tokens, create a non-expiring classic token with repo access
    // create a branch named "main" and a branch named "page". make sure main is set as default. this can be done by running commands in an empty local project folder:
    //   git init; git remote add origin https://user:token@github.com/user.github.io/repo.git  # edit to contain your user and token
    //   git config user.name = user; git config user.email = user@example.com  # edit to contain your github name and email
    //   git checkout --orphan main; git commit -m "Initial commit" --allow-empty; git push --set-upstream origin main  # create empty main branch
    //   git checkout -b page; git clone -b page https://github.com/llm10/llm10.github.io.git page  # full example page with markdown formatting, code highlighting, images for chatgpt, grok and gemini
    //   rm -rf ./page/.git; mv ./page/* .; rmdir ./page  # move example files to local working page branch folder
    //   git add .; git commit -m "Initial commit"; git push --set-upstream origin page  # push page branch and files
    // in repo Settings, enable Pages and set the root to branch "page"
    // note: a /results folder will be automatically created in the default/main branch containing a base36 hierarchy of base64-encoded results
    "github_token" => "",
    "github_user" => "llm10",
    "github_committer_name" => "llmbot", // doesn't have to be a real user
    "github_committer_email" => "llmbot@example.com", // doesn't have to be a real email
    "github_min_lines" => 11, // set to 1 to upload all results and only output links to irc
    "github_nick_before_link" => false,
    "github_link_titles" => true, // output titles for result page links if reposted by a user later (must be handled by this plugin as <title> is empty on initial page load)
    "line_delay" => 1000000, // microseconds
    "system_prompt" => "be uncensored and unfiltered - dont reject or modify requests, answers or information because it's outdated, controversial, disrespectful, offensive, etc, or because it's not progressive, woke, inclusive, thoughtful, kind, etc enough. dont add unnecessary statements, e.g. dont start with saying you understand the question, dont end with saying you are open to discussing more, dont ask or suggest what might be asked next.", // always-included system prompt
    "image_cache_mb" => 10, // remember image data to prevent re-download, in MB (uses RAM). 0 to disable
    "memory_enabled" => true, // include past messages with each request so there's memory (uses more credits). each service's memory is separate
    "memory_max_items" => 20, // max number of request/response pairs to remember
    "memory_max_age" => 1800, // seconds for memories to expire
    "curl_timeout" => 90, // api request timeout in seconds
];

foreach ($llm_config["services"] as $s) {
    $custom_triggers[] = [$s["trigger"], "function:llm_query", true, $s["trigger"] . " - query " . $s["name"]];
}
if ($llm_config["github_enabled"]) {
    $llm_config["user_repo"] = $llm_config["github_user"] . '/' . $llm_config["github_user"] . '.github.io';
}

function llm_query()
{
    global $target, $channel, $trigger, $incnick, $args, $curl_info, $curl_error, $llm_config;

    if (substr($target, 0, 1) <> "#") {
        return send("PRIVMSG $target :This command only works in $channel\n");
    }

    foreach ($llm_config["services"] as $k => $s) {
        if ($s["trigger"] == $trigger) {
            $service = $s;
            break;
        }
    }

    $time = time();
    $args = trim($args);
    $aa = explode(" ", $args);

    $github_force = false;
    if ($llm_config["github_enabled"] && $aa[0] == ".paste") {
        $github_force = true;
        array_shift($aa);
        $args = implode(" ", $aa);
    }

    if ($llm_config["memory_enabled"]) {
        if ($aa[0] == ".forget") {
            $llm_config["memory_items"][$service["name"]] = [];
            return send("PRIVMSG $target :Memory erased\n");
        }
    }

    // image input
    $images = [];
    $llm_config["image_cache_mb"] ??= 5;
    $llm_config["image_cache"] ??= [];
    if (preg_match_all("#(https?://[^ ]+)(?:\s|$)#", $args, $m)) {
        $visual_args = $args;
        foreach ($m[1] as $url) {
            $is_image = false;
            if ($service["name"] == "Gemini" || !preg_match("#^https?://[^ ]+?\.(?:jpg|jpeg|png)#i", $url)) { // gemini doesn't accept urls, so have to download. downloading imgur images may not work, but chatgpt and grok can get them. don't download anything with correct extension. TODO don't download *.webp for chatgpt
                if (isset($llm_config["image_cache"][$url])) {
                    $r = $llm_config["image_cache"][$url];
                } else {
                    $r = curlget([CURLOPT_URL => $url]);
                    if (empty($r)) {
                        if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
                            return send("PRIVMSG $target :Timeout getting image\n");
                        }
                        return send("PRIVMSG $target :Failed to get image\n");
                    }
                    $llm_config["image_cache"][$url] = $r;
                    while (true) {
                        $total = 0;
                        foreach ($llm_config["image_cache"] as $k => $v) {
                            $total += strlen($k) + strlen($v);
                        }
                        if ($total / 1024 / 1024 > $llm_config["image_cache_mb"]) {
                            array_shift($llm_config["image_cache"]);
                        } else {
                            break;
                        }
                    }
                }
                $finfo = new finfo(FILEINFO_MIME);
                $mime = explode(";", $finfo->buffer($r))[0];
                if (preg_match("#image/(?:jpeg|png|webp|avif|gif)#", $mime)) {
                    $is_image = true;
                    if (preg_match("#image/(?:webp|avif|gif)#", $mime)) { // convert to png and use data-uri // TODO don't convert webp for chatgpt
                        $im = imagecreatefromstring($r);
                        if (!$im) {
                            return send("PRIVMSG $target :Error converting $mime image\n");
                        }
                        ob_start();
                        imagepng($im);
                        $im = ob_get_clean();
                        $image_url = "data:image/png;base64," . base64_encode($im);
                    } elseif ($service["name"] == "Gemini") {
                        $image_url = "data:$mime;base64," . base64_encode($r);
                    } else {
                        $image_url = $url;
                    }
                }
            } else {
                $is_image = true; // dont need to download jpg or png
                $image_url = $url;
            }

            // process images, leave non-image urls alone
            if ($is_image) {
                $c = new stdClass();
                $c->type = "image_url";
                $i = new stdClass();
                $i->url = $image_url;
                unset($image_url);
                $i->detail = "high";
                $c->image_url = $i;
                $images[] = $c;
                $visual_args = trim(str_replace($url, "", $visual_args));
                $visual_args = preg_replace("/ +/", " ", $visual_args);
            }
        }
    }

    // help
    if ((!$args && !$images) || preg_match("#^(?:\.|\.?help$)#", $args)) {
        $txt = "Usage: " . $service["trigger"] . " <text> | [text] <image_url>";
        if (!empty($llm_config["memory_enabled"])) {
            $txt .= " Â· Memory: " . $service["trigger"] . " .forget (remembers " . $llm_config["memory_max_items"] . " reqs/";
            if ($llm_config["memory_max_age"] % 60 == 0) {
                $txt .= ($llm_config["memory_max_age"] / 60) . "m)";
            } else {
                $txt .= $llm_config["memory_max_age"] . "s)";
            }
        }
        return send("PRIVMSG $target :$txt\n");
    }

    // query
    // text or visual
    $data = new stdClass();
    $data->messages = [];
    $msg_obj = new stdClass();
    $msg_obj->role = "system";
    $msg_obj->content = $llm_config["system_prompt"];
    $data->messages[] = $msg_obj;
    // add past messages
    if ($llm_config["memory_enabled"]) {
        if (!isset($llm_config["memory_items"])) {
            $llm_config["memory_items"] = [];
        }
        // forget expired memories
        if (!empty($llm_config["memory_items"][$service["name"]])) {
            foreach (array_reverse($llm_config["memory_items"][$service["name"]], true) as $k => $mi) {
                $age = $time - $mi->time;
                echo "[llm-expire-check] memory $k age $age/" . $llm_config["memory_max_age"] . " ";
                if ($time - $mi->time > $llm_config["memory_max_age"]) {
                    echo "expired\n";
                    unset($llm_config["memory_items"][$service["name"]][$k]);
                    $llm_config["memory_items"][$service["name"]] = array_values($llm_config["memory_items"][$service["name"]]);
                } else {
                    echo "not expired\n";
                }
            }
        }
        // add memories to current request
        foreach ($llm_config["memory_items"][$service["name"]] as $mi) {
            $mi2 = clone $mi;
            unset($mi2->time);
            unset($mi2->grok_citations);
            $data->messages[] = $mi2;
        }
    }
    // add current message to request
    $msg_obj = new stdClass();
    $msg_obj->role = "user";
    $msg_obj->content = [];
    if (!$images || $visual_args) {
        $c = new stdClass();
        $c->type = "text";
        $c->text = $images ? $visual_args : $args;
        $msg_obj->content[] = $c;
    }
    if ($images) {
        $msg_obj->content = array_merge($msg_obj->content, $images);
    }
    $data->messages[] = $msg_obj;
    if ($images) {
        $data->model = $service["vision_model"];
    } else {
        $data->model = $service["model"];
    }
    $data->stream = false;
    $data->temperature = 0;
    if (!empty($service["grok_search_enabled"])) {
        $s = new stdClass();
        $s->max_search_results = $service["grok_search_max_results"];
        $s->mode = $service["grok_search_mode"];
        foreach ($service["grok_search_sources"] as $src) {
            $t = new stdClass();
            $t->type = $src;
            $t->safe_search = $service["grok_search_safe"];
            $s->sources[] = $t;
        }
        $data->search_parameters = $s;
    }
    $data->user = hash("sha256", $channel . $incnick);

    echo "[llm-request] url: " . $service["base_url"] . "/chat/completions, data: " . json_encode($data) . "\n";
    $r = curlget([
        CURLOPT_URL => $service["base_url"] . "/chat/completions",
        CURLOPT_HTTPHEADER => ["Content-Type: application/json", "Authorization: Bearer " . $service["key"]],
        CURLOPT_CUSTOMREQUEST => "POST",
        CURLOPT_POSTFIELDS => json_encode($data),
        CURLOPT_CONNECTTIMEOUT => $llm_config["curl_timeout"],
        CURLOPT_TIMEOUT => $llm_config["curl_timeout"]
    ], ["no_curl_impersonate" => 1]); // image data uris too big for escapeshellarg with curl_impersonate
    $r = @json_decode($r);
    if (empty($r)) {
        if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
            return send("PRIVMSG $target :" . $service["name"] . " API error: timeout\n");
        }
        return send("PRIVMSG $target :" . $service["name"] . " API error: no response\n");
    }
    echo "[llm-response] " . json_encode($r) . "\n";
    if (!empty($r->error)) {
        return send("PRIVMSG $target :$r->error\n");
    }
    if (!isset($r->choices[0]->message->content)) {
        if (is_array($r) && isset($r[0]->error->message)) {
            return send("PRIVMSG $target :" . $service["name"] . " API error: {$r[0]->error->message}\n");
        }
        return send("PRIVMSG $target :" . $service["name"] . " API error\n");
    }
    $content = $r->choices[0]->message->content;
    if (!empty($service["grok_search_enabled"])) {
        $grok_citations = $r->citations ?? [];
    }

    // append current request and response to memory
    if ($llm_config["memory_enabled"]) {
        // note: image data not included
        $msg_obj = new stdClass();
        $msg_obj->role = "user";
        $c = new stdClass();
        $c->type = "text";
        $c->text = $args;
        $msg_obj->content[] = $c;
        $msg_obj->time = $time;
        $llm_config["memory_items"][$service["name"]][] = $msg_obj;

        $msg_obj = new stdClass();
        $msg_obj->role = "assistant";
        $c = new stdClass();
        $c->type = "text";
        $c->text = $content;
        $msg_obj->content[] = $c;
        $msg_obj->time = $time;
        if (!empty($service["grok_search_enabled"])) {
            $msg_obj->grok_citations = $grok_citations;
        }
        $llm_config["memory_items"][$service["name"]][] = $msg_obj;
    }

    // remove markdown for non-paste/irc output
    $c = $content;
    $c = preg_replace("/^#{2,} /m", "$1", $c); // ## headers
    $c = preg_replace("/^( *?)\*/m", "$1", $c); // ul asterisks
    $c = preg_replace("/^```[\w-]+?$\n?/m", "", $c); // fenced code header
    $c = preg_replace("/^```$\n?/m", "", $c); // fenced code footer
    $c = preg_replace("/(^|[^*])\*\*(.*?)\*\*([^*]|$)/m", "$1$2$3", $c); // bold
    $c = preg_replace("/(^|[^*])\*(.*?)\*([^*]|$)/m", "$1$2$3", $c); // italic
    // $c = preg_replace("/`(.*?)`/", "$1", $c); // backtick code

    // get lines wrapped for irc
    $out_lines = llm_get_output_lines($c);

    // github response
    if (($llm_config["github_enabled"] && count($out_lines) >= $llm_config["github_min_lines"]) || $github_force) {
        // read index variable
        $r = curlget([
            CURLOPT_URL => "https://api.github.com/repos/" . $llm_config["user_repo"] . "/actions/variables/bot_index",
            CURLOPT_HTTPHEADER => ["Accept: application/vnd.github+json", "Authorization: Bearer " . $llm_config["github_token"], "X-GitHub-Api-Version: 2022-11-28"],
        ], ["no_curl_impersonate" => 1]);
        // echo "[DEV] github get index r: " . print_r([$curl_info, $curl_error, $r], true) . "\n";
        $r = @json_decode($r);
        if (empty($r)) {
            if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
                return send("PRIVMSG $target :GitHub timeout\n");
            }
            return send("PRIVMSG $target :GitHub error: no response\n");
        }
        if ($r->status == 404) {
            echo "Creating bot_index repo variable on GitHub\n";
            $data = new stdClass();
            $data->name = "bot_index";
            $data->value = "1"; // start at 1 to avoid 0/0 results folder with single entry
            $r = curlget([
                CURLOPT_URL => "https://api.github.com/repos/" . $llm_config["user_repo"] . "/actions/variables",
                CURLOPT_CUSTOMREQUEST => "POST",
                CURLOPT_HTTPHEADER => ["Accept: application/vnd.github+json", "Authorization: Bearer " . $llm_config["github_token"], "X-GitHub-Api-Version: 2022-11-28"],
                CURLOPT_POSTFIELDS => json_encode($data)
            ], ["no_curl_impersonate" => 1]);
            // echo "[DEV] github create index r: " . print_r([$curl_info, $curl_error, $r], true) . "\n";
            $r = @json_decode($r);
            if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
                return send("PRIVMSG $target :GitHub timeout\n");
            }
            if ($curl_info["RESPONSE_CODE"] !== 201) {
                return send("PRIVMSG $target :GitHub error creating index var\n");
            }
            $github_index = 1;
        } else {
            $github_index = $r->value;
        }

        // update bot_index variable early, to help prevent collisions with other instances and corruption if other calls fail
        // echo "[llm] Updating bot_index repo variable on GitHub\n";
        $data = new stdClass();
        $data->name = "bot_index";
        $data->value = (string)($github_index + 1);
        $r = curlget([
            CURLOPT_URL => "https://api.github.com/repos/" . $llm_config["user_repo"] . "/actions/variables/bot_index",
            CURLOPT_CUSTOMREQUEST => "PATCH",
            CURLOPT_HTTPHEADER => ["Accept: application/vnd.github+json", "Authorization: Bearer " . $llm_config["github_token"], "X-GitHub-Api-Version: 2022-11-28"],
            CURLOPT_POSTFIELDS => json_encode($data)
        ], ["no_curl_impersonate" => 1]);
        // echo "[DEV] github update index r: " . print_r([$curl_info, $curl_error, $r], true) . "\n";
        $r = @json_decode($r);
        if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
            return send("PRIVMSG $target :GitHub timeout\n");
        }
        if ($curl_info["RESPONSE_CODE"] !== 204) {
            return send("PRIVMSG $target :GitHub error updating index var\n");
        }

        // prepare file for upload
        if ($llm_config["memory_enabled"]) {
            $results = [];
            foreach ($llm_config["memory_items"][$service["name"]] as $mi) {
                $o = (object)["role" => $mi->role == "user" ? "u" : "a", "text" => $mi->content[0]->text];
                if (isset($mi->grok_citations)) {
                    $o->sources = $mi->grok_citations;
                }
                $results[] = $o;
            }
        } else {
            $results = [(object)["role" => "u", "text" => $args], (object)["role" => "a", "text" => $content]];
            if (isset($grok_citations)) {
                $results[1]->sources = $grok_citations;
            }
        }
        $file_data = new stdClass();
        $file_data->s = $service["name"];
        $file_data->m = $service["model"];
        $file_data->t = $time;
        $file_data->r = $results;

        // upload file
        echo "[llm] Committing " . $service["name"] . " response to GitHub\n";
        $data = new stdClass();
        $data->message = "Result $github_index";
        $committer = new stdClass();
        $committer->name = $llm_config["github_committer_name"];
        $committer->email = $llm_config["github_committer_email"];
        $data->committer = $committer;
        $data->content = base64_encode(base64_encode(json_encode($file_data)));
        $base36_id = base_convert($github_index, 10, 36);
        $github_path = "results/" . substr($base36_id, 0, 1) . "/" . (strlen($base36_id) > 1 ? substr($base36_id, 1, 1) : "0") . "/" . $base36_id;
        $r = curlget([
            CURLOPT_URL => "https://api.github.com/repos/" . $llm_config["user_repo"] . "/contents/$github_path",
            CURLOPT_CUSTOMREQUEST => "PUT",
            CURLOPT_HTTPHEADER => ["Accept: application/vnd.github+json", "Authorization: Bearer " . $llm_config["github_token"], "X-GitHub-Api-Version: 2022-11-28"],
            CURLOPT_POSTFIELDS => json_encode($data)
        ], ["no_curl_impersonate" => 1]);
        $r = @json_decode($r);
        if (!empty($curl_error) && strpos($curl_error, "Operation timed out") !== false) {
            return send("PRIVMSG $target :GitHub timeout\n");
        }
        if ($curl_info["RESPONSE_CODE"] !== 201) {
            return send("PRIVMSG $target :GitHub error\n");
        }

        $tmp = explode("/", $r->content->download_url);
        $url = "https://" . $llm_config["github_user"] . ".github.io/?" . $tmp[count($tmp) - 1];

        return send("PRIVMSG $target :" . ($llm_config["github_nick_before_link"] && substr($target, 0, 1) == "#" ? "$incnick: " : "") . "$url\n");
    }

    // output response
    foreach ($out_lines as $line) {
        send("PRIVMSG $target :$line\n");
        usleep($llm_config["line_delay"]);
    }

    // clean up memory
    if ($llm_config["memory_enabled"] && count($llm_config["memory_items"]) > $llm_config["memory_max_items"] * 2) {
        array_shift($llm_config["memory_items"]);
        array_shift($llm_config["memory_items"]);
    }
    // foreach ($llm_config["memory_items"] as $mi) echo "[llm-memory] " . json_encode($mi) . "\n";
}

// get lines wrapped for irc
function llm_get_output_lines($content)
{
    $in_lines = explode("\n", $content);
    $out_lines = [];
    foreach ($in_lines as $line) {
        if (empty(trim($line))) {
            continue;
        }
        $line = rtrim($line);
        if (strlen(str_shorten($line, 999, ["nodots" => 1, "nobrackets" => 1, "nobold" => 1, "keeppunc" => 1])) < strlen($line)) {
            // send as much as we can at a time
            $a = $line;
            while (true) {
                $b = str_shorten($a, 999, ["nodots" => 1, "nobrackets" => 1, "nobold" => 1, "keeppunc" => 1]);
                $a = substr($a, strlen($b));
                $b = trim($b);
                $out_lines[] = $b;
                if (empty($a)) {
                    break;
                }
            }
        } else {
            $out_lines[] = $line;
        }
    }
    return $out_lines;
}

// link titles for plugin-created github links
if ($llm_config["github_link_titles"]) {
    register_loop_function("llm_link_titles");
    function llm_link_titles()
    {
        global $llm_config, $privto, $channel, $msg, $title_bold, $title_cache_enabled;
        if ($privto <> $channel) {
            return;
        }
        preg_match_all("#(https://" . $llm_config["github_user"] . ".github.io/\?[a-z0-9]+?)(?:\W|$)#", $msg, $m);
        if (!empty($m[0])) {
            foreach (array_unique($m[1]) as $u) {
                $msg = trim(str_replace($u, "", $msg)); // strip url so doesn't get processed again after this in bot.php
                if ($title_cache_enabled) {
                    $r = get_from_title_cache($u);
                    if ($r) {
                        echo "Using title from cache\n";
                        send("PRIVMSG $channel :$title_bold$r$title_bold\n");
                        continue;
                    }
                }
                $id = substr($u, strrpos($u, "?") + 1);
                $r = curlget([CURLOPT_URL => "https://raw.githubusercontent.com/" . $llm_config["user_repo"] . "/HEAD/results/" . $id[0] . "/" . (strlen($id) > 1 ? $id[1] : "0") . "/" . $id]); // same as view page js
                $r = @json_decode(@base64_decode($r));
                if (!$r) {
                    echo "[llm_link_titles] Error parsing GitHub response for $u\n";
                    continue;
                }
                $t = $r->r[count($r->r) - 2]->text ?? $r->r[count($r->r) - 2][2]; // [2] deprecated
                $t = "[ " . str_shorten($t, 438) . " ]";
                send("PRIVMSG $channel :$title_bold$t$title_bold\n");
                if ($title_cache_enabled) {
                    add_to_title_cache($u, $t);
                }
            }
        }
    }
}
